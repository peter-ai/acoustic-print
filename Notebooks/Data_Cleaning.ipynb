{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### Context\n",
    "The dataset is comprised of information about songs (tracks), music genres, albums, and artists as aggregated from the Free Music Archive (FMA). In particular, this data was used in an academic study on music information retrieval; both the paper and data is accessible from the following [github repository](https://github.com/mdeff/fma). The dataset itself contains 917 GB and 343 days of Creative Commons-licensed audio from 106,574 tracks from 16,341 artists and 14,854 albums, arranged in a hierarchical taxonomy of 161 genres. For the purposes of this project, we are only concerned with a subset of this data that actually has documentation of specific measurable musical characteristics such as tempo, energy, and danceability, to name a few. \n",
    "\n",
    "### Cleaning\n",
    "We go through various steps to clean the data across the several files provided from the FMA. Much of the cleaning and data manipulation pertains to text editing and ensuring data is consistent across dataframes which were then loaded into a relation database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "import os\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# load variables from .env file into set of environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# get environment variables for database connection\n",
    "hostname = os.getenv(\"HOSTNAME\")\n",
    "username = os.getenv(\"USERNAME\")\n",
    "password = os.getenv(\"PASSWORD\")\n",
    "database = os.getenv(\"DATABASE\")\n",
    "port = 3306\n",
    "\n",
    "# create db connection str and MySQL engine pool\n",
    "connect_str = f\"mysql+pymysql://{username}:{password}@{hostname}:3306/{database}\"\n",
    "engine = sqlalchemy.create_engine(connect_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load song/track characteristics data\n",
    "echo_df = pd.read_csv(\"../Data/fma_metadata_updated/echonest_updated.csv\")\n",
    "\n",
    "# only keep desired columns\n",
    "echo_df = echo_df.iloc[:, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for songs/tracks\n",
    "tracks_df = pd.read_csv(\"../Data/fma_metadata_updated/raw_tracks.csv\")\n",
    "\n",
    "# filter and only keep desired columns\n",
    "tracks_df = tracks_df.filter([\n",
    "    \"track_id\",\n",
    "    \"album_id\",\n",
    "    \"artist_id\",\n",
    "    \"track_duration\",\n",
    "    \"track_explicit\",\n",
    "    \"track_favorites\",\n",
    "    \"track_listens\",\n",
    "    \"track_title\",\n",
    "    \"track_genres\"\n",
    "])\n",
    "\n",
    "# inner join tracks with characteristics; only keep songs with characteristic information\n",
    "tracks_echo_df = pd.merge(\n",
    "    left=echo_df,\n",
    "    right=tracks_df,\n",
    "    how=\"inner\",\n",
    "    on=\"track_id\"\n",
    ")\n",
    "\n",
    "# rename columns\n",
    "tracks_echo_df.rename(\n",
    "    {\n",
    "        \"track_duration\": \"duration\",\n",
    "        \"track_explicit\": \"explicit\",\n",
    "        \"track_favorites\": \"favorites\",\n",
    "        \"track_listens\": \"listens\",\n",
    "        \"track_title\": \"title\",\n",
    "        \"track_genres\": \"genre_id\"\n",
    "    }, \n",
    "    axis=1, \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# some preliminary data cleaning and data type conversions\n",
    "tracks_echo_df[\"duration\"] = tracks_echo_df.duration.apply(lambda x: int(x.split(\":\")[0])*60 + int(x.split(\":\")[1])) # convert song duration from min:sec format to seconds\n",
    "tracks_echo_df[\"album_id\"] = tracks_echo_df.album_id.apply(int) # convert to int datatype\n",
    "tracks_echo_df[\"explicit\"] = tracks_echo_df[\"explicit\"].replace({\"Radio-Unsafe\": 1, \"Radio-Safe\": 0, np.nan: -1}) # replace with levels 1 being explicit, 0 be not explicit, and -1 being unsure\n",
    "tracks_echo_df[\"genre_id\"] = tracks_echo_df.genre_id.apply(lambda x: [genre[\"genre_id\"] for genre in eval(x)]) # extract genre_id from list of genre dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for genres\n",
    "genres_df = pd.read_csv(\"../Data/fma_metadata_updated/genres_updated.csv\")\n",
    "\n",
    "# map tracks with multiple genres to individual rows\n",
    "tracks_genres_df = tracks_echo_df.explode(\"genre_id\")\n",
    "tracks_genres_df[\"genre_id\"] = tracks_genres_df[\"genre_id\"].astype(int)\n",
    "\n",
    "# match songs with only top-level genres (16 unique genres), eliminating niche genres (160+ total)\n",
    "tracks_genres_df = pd.merge(\n",
    "    left=pd.merge(                  # join genres with their top-level genre in the hiearchy\n",
    "        left=genres_df,\n",
    "        right=genres_df,\n",
    "        how=\"inner\",\n",
    "        left_on=\"genre_id\",\n",
    "        right_on=\"top_level\"\n",
    "    ).iloc[:, :7],\n",
    "    right=tracks_genres_df[[\"track_id\", \"genre_id\"]],\n",
    "    how=\"inner\",\n",
    "    left_on=\"genre_id_y\",\n",
    "    right_on=\"genre_id\"\n",
    ")\n",
    "\n",
    "# drop unnecessary columns and rename others\n",
    "tracks_genres_df = tracks_genres_df.drop([\"genre_id_y\",\"genre_id\", \"top_level_x\", \"parent_x\"], axis=1)\n",
    "tracks_genres_df = tracks_genres_df.drop_duplicates()\n",
    "tracks_genres_df.rename(\n",
    "    {\n",
    "        \"genre_id_x\":\"genre_id\", \n",
    "        \"#tracks_x\":\"num_tracks\",\n",
    "        \"title_x\": \"title\",\n",
    "        \"genre_color_x\": \"genre_color\",\n",
    "    },\n",
    "    axis=1, \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# create dataframe of genres\n",
    "genres_df = tracks_genres_df.filter([\"genre_id\", \"num_tracks\", \"title\", \"genre_color\"]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# create dataframe mapping tracks to top-level genres\n",
    "tracks_genres_df = tracks_genres_df.filter([\"track_id\", \"genre_id\"]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# create tracks dataframe, dropping a few erraneous observations\n",
    "tracks_df = tracks_echo_df.drop(\"genre_id\", axis=1)\n",
    "tracks_df = tracks_df[~tracks_df.artist_id.isin([2442, 13401])]\n",
    "tracks_df.loc[tracks_df.artist_id == 1680,\"artist_id\"] = 4542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load artist data\n",
    "artists_df = pd.read_csv(\"../Data/fma_metadata_updated/raw_artists.csv\")\n",
    "\n",
    "# filter and only keep desired columns\n",
    "artists_df = artists_df.filter([\"artist_id\",\"artist_favorites\", \"artist_name\"])\n",
    "\n",
    "# only keep artists that have made atleast one track\n",
    "artists_df = artists_df[artists_df[\"artist_id\"].isin(tracks_df.artist_id)]\n",
    "\n",
    "# rename columns\n",
    "artists_df.rename({\"artist_favorites\":\"favorites\", \"artist_name\":\"name\"}, axis=1, inplace=True)\n",
    "artists_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# drop a few erraneous observations\n",
    "artists_df = artists_df[~artists_df.artist_id.isin([2442, 13401])]\n",
    "artists_df.loc[artists_df.artist_id == 1680, \"artist_id\"] = 4542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>favorites</th>\n",
       "      <th>title</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>listens</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>4</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>6073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13756</td>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Jackin4Beats</td>\n",
       "      <td>11</td>\n",
       "      <td>4995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>2009-01-09</td>\n",
       "      <td>0</td>\n",
       "      <td>On Opaque Things</td>\n",
       "      <td>4</td>\n",
       "      <td>5613</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Wooden Lake Sexual Diner</td>\n",
       "      <td>3</td>\n",
       "      <td>2180</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10308</td>\n",
       "      <td>2011-10-03</td>\n",
       "      <td>0</td>\n",
       "      <td>Live at WFMU on Liz Berg's Show on October 3, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>3163</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   album_id release_date  favorites  \\\n",
       "0         1   2009-01-05          4   \n",
       "1     13756   2012-04-01          0   \n",
       "2       100   2009-01-09          0   \n",
       "3       101   2007-01-01          0   \n",
       "4     10308   2011-10-03          0   \n",
       "\n",
       "                                               title  num_tracks  listens  \\\n",
       "0                               AWOL - A Way Of Life           7     6073   \n",
       "1                                       Jackin4Beats          11     4995   \n",
       "2                                   On Opaque Things           4     5613   \n",
       "3                           Wooden Lake Sexual Diner           3     2180   \n",
       "4  Live at WFMU on Liz Berg's Show on October 3, ...           9     3163   \n",
       "\n",
       "   artist_id  \n",
       "0          1  \n",
       "1          1  \n",
       "2         80  \n",
       "3         80  \n",
       "4         80  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load album data\n",
    "albums_df = pd.read_csv(\"../Data/fma_metadata_updated/raw_albums.csv\")\n",
    "\n",
    "# only keep albums which have a matching artist name\n",
    "albums_df = albums_df[albums_df[\"artist_name\"].isin(artists_df.name)]\n",
    "\n",
    "# swap matching artist names with artist ids to comply with sql schema\n",
    "# swap self-titled albums (s/t) with the artist name\n",
    "albums_df = pd.merge(\n",
    "    left=albums_df,\n",
    "    right=artists_df[[\"name\", \"artist_id\"]],\n",
    "    how=\"inner\",\n",
    "    left_on=\"artist_name\",\n",
    "    right_on=\"name\"\n",
    ")\n",
    "albums_df[\"album_title\"] = albums_df.apply(lambda row: row[\"artist_name\"] + \"(s/t)\" if row[\"album_title\"].lower() == \"s/t\" else row[\"album_title\"], axis=1)\n",
    "\n",
    "# filter and only keep desired columns\n",
    "albums_df = albums_df.filter([\n",
    "    \"album_id\", \n",
    "    \"album_date_released\", \n",
    "    \"album_favorites\", \n",
    "    \"album_title\", \n",
    "    \"album_tracks\", \n",
    "    \"album_listens\", \n",
    "    \"artist_id\"\n",
    "])\n",
    "\n",
    "# rename columns\n",
    "albums_df.rename({ \n",
    "    \"album_date_released\": \"release_date\", \n",
    "    \"album_favorites\": \"favorites\", \n",
    "    \"album_title\": \"title\", \n",
    "    \"album_tracks\": \"num_tracks\", \n",
    "    \"album_listens\": \"listens\", \n",
    "    },\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# convert release date to datetime format\n",
    "albums_df[\"release_date\"] = pd.to_datetime(albums_df.release_date, format=\"%m/%d/%Y\")\n",
    "albums_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# show head\n",
    "albums_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap id in each dataframe to coincide with sql table schemas\n",
    "tracks_df.rename({\"track_id\": \"id\"},axis=1, inplace=True)\n",
    "genres_df.rename({\"genre_id\": \"id\"},axis=1, inplace=True)\n",
    "artists_df.rename({\"artist_id\": \"id\"},axis=1, inplace=True)\n",
    "albums_df.rename({\"album_id\": \"id\"},axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### final cleanup based of dataframes\n",
    "\n",
    "# string cleanup of artist names a nd track titles\n",
    "artists_df[\"name\"] = artists_df.name.apply(lambda x: x.split(\",\")[0].replace(\"&amp;\", \"&\").replace(\"&amp\", \"&\").replace(\"(F.A.G.G)\", \"\").replace(\"(Various)\", \"\").replace(\"&;\", \"&\").replace(\"(avec logo panthère)\", \"\").strip())\n",
    "\n",
    "# string cleanup of album names\n",
    "albums_df[\"title\"] = albums_df.title.apply(lambda x: x.strip())\n",
    "\n",
    "# only keep tracks that have an associate artist\n",
    "tracks_df = tracks_df[tracks_df.artist_id.isin(artists_df.id)]\n",
    "\n",
    "# if a track's album id isn't contained in the album data set it to NA\n",
    "tracks_df.loc[~tracks_df.album_id.isin(albums_df.id), \"album_id\"] = np.nan\n",
    "\n",
    "# fix this track title as it is titled NaN and should not be treated as a missing value\n",
    "tracks_df.loc[tracks_df.title.isna(), \"title\"] = 'NaN'\n",
    "tracks_df[\"title\"] = tracks_df.title.apply(lambda x: x.replace(\"&amp;\", \"&\").replace(\"&amp\", \"&\"))\n",
    "\n",
    "# only keep tuples which have a track_id that's still present in the tracks dataframe\n",
    "tracks_genres_df = tracks_genres_df[tracks_genres_df.track_id.isin(tracks_df.id)]\n",
    "\n",
    "# drop all albums without a track in the dataset and correct all track counts\n",
    "albums_df = pd.merge(\n",
    "    left=tracks_df[[\"id\", \"album_id\"]].groupby(by=\"album_id\", as_index=False).count(),\n",
    "    right=albums_df,\n",
    "    left_on=\"album_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_counts\", None)\n",
    ").drop([\"album_id\", \"num_tracks\"], axis=1).rename({\"id_counts\": \"num_tracks\"},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map sql table to pandas dataframes\n",
    "tables = dict(\n",
    "    Genres=genres_df, \n",
    "    Artists=artists_df,\n",
    "    Albums=albums_df, \n",
    "    Tracks=tracks_df, \n",
    "    Track_Genres=tracks_genres_df,\n",
    ")\n",
    "\n",
    "# insert pandas tables into relevant MySQL tables\n",
    "for table, df in tables.items():\n",
    "    insertions = df.to_sql(\n",
    "        table,\n",
    "        engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        chunksize=1000\n",
    "    )\n",
    "    print(f\"Pandas dataframe inserted into DB {table} table successfully with {insertions} tuples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that data was inserted correctly\n",
    "with engine.connect() as connection:\n",
    "    for table in tables.keys():\n",
    "        print(f\"{table}\\n{'-'*len(table)}\")\n",
    "        query = sqlalchemy.text(f\"SELECT * FROM {table} ORDER BY {'id' if table!='Track_Genres' else 'track_id'} ASC LIMIT 10\")\n",
    "        response = connection.execute(query)\n",
    "        for row in response:\n",
    "            print(row)\n",
    "        print()\n",
    "\n",
    "# dispose of db connection pool and close all connections\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acoustic-print",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
